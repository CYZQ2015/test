{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 165818_CKD-pure.csv: ['id', 'gender', 'age', 'height', 'weight', 'history', '24hPro', 'SCr', 'BUN', 'Albamin', 'GFR', 'CKDstage', 'dCKD', 'USET', 'rLen', 'rShort', 'rThick', 'rPT', 'rPTLA', 'rPTLPA', 'rPTLA.1', 'rPTSA', 'rPTSPA', 'rPSPA', 'Unnamed: 24', 'LE', 'rKME', 'rKUPE', 'rRPE ', 'Unnamed: 29', 'lLen', 'lShort', 'lThick', 'lPT', 'lPTA', 'lPGA', 'lPLA', 'lTSPA', 'lSPA', 'lPSA', 'Unnamed: 40', 'SE', 'lCKE', 'lRUPE', 'lRPE', 'DSK', 'DLK', 'rAR', 'lAR', 'rRP', 'lRP', 'PDT', 'PP', 'PK', 'PL', 'GloNumGM', 'GloNumIM', 'SW', 'SWR']\n",
      "Data shape (rows, columns) =   (804, 21)\n",
      "Data shape (rows, columns) =   (98, 21)\n",
      "training data shape (rows, columns) =   (804, 21)\n",
      "TRUE rate:  0.48009950248756217\n",
      "testing data shape (rows, columns) =   (98, 21)\n",
      "TRUE rate:  0.3163265306122449\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_ckd = pd.read_csv(os.path.join('sets', 'CKD_train.csv'))\n",
    "test_ckd = pd.read_csv(os.path.join('sets', 'CKD_test.csv'))\n",
    "\n",
    "#print columns in the table\n",
    "print(\"Columns in 165818_CKD-pure.csv: \" + str(list(train_ckd.columns)))\n",
    "\n",
    "#remove NA dCKD row\n",
    "train_datanota = train_ckd[train_ckd['dCKD'].notna()]\n",
    "test_datanota = test_ckd[test_ckd['dCKD'].notna()]\n",
    "\n",
    "#set the labels\n",
    "train_labels = train_datanota.dCKD.values\n",
    "test_labels = test_datanota.dCKD.values\n",
    "\n",
    "#fetch the columns that we'll be using for our models\n",
    "_train_data = train_datanota[[ 'age', 'height', 'weight', 'rLen', 'rShort', 'rPT', 'rPTLPA', 'LE', 'rKME', 'rKUPE', 'rRPE ', 'lPT', 'lPGA', 'lTSPA', 'lSPA', 'lPSA', 'lCKE', 'lRUPE', 'lRPE', 'DSK', 'DLK']]\n",
    "print(\"Data shape (rows, columns) =  \", _train_data.shape)\n",
    "\n",
    "_test_data = test_datanota[[ 'age', 'height', 'weight', 'rLen', 'rShort', 'rPT', 'rPTLPA', 'LE', 'rKME', 'rKUPE', 'rRPE ', 'lPT', 'lPGA', 'lTSPA', 'lSPA', 'lPSA', 'lCKE', 'lRUPE', 'lRPE', 'DSK', 'DLK']]\n",
    "print(\"Data shape (rows, columns) =  \", _test_data.shape)\n",
    "\n",
    "#step3-6: replace illigal data to median \n",
    "dat_proc_3 = _train_data.replace('#DIV/0!', 0)\n",
    "dat_proc_4 = dat_proc_3.fillna(0)\n",
    "dat_proc_5 = dat_proc_4.astype('float32')\n",
    "dat_proc_6 = dat_proc_5.replace(0, dat_proc_5.median())\n",
    "\n",
    "dat_proc_31 = _test_data.replace('#DIV/0!', 0)\n",
    "dat_proc_41 = dat_proc_31.fillna(0)\n",
    "dat_proc_51 = dat_proc_41.astype('float32')\n",
    "dat_proc_61 = dat_proc_51.replace(0, dat_proc_51.median())\n",
    "#print(dat_proc_6.head(10))\n",
    "\n",
    "#step 7: normalization\n",
    "# max-min normalization\n",
    "#train_data = (dat_proc_6 - dat_proc_6.min())/(dat_proc_6.max() - dat_proc_6.min())\n",
    "#test_data = (dat_proc_61 - dat_proc_61.min())/(dat_proc_61.max() - dat_proc_61.min())\n",
    "#print(data.head(10))\n",
    "\n",
    "# z-score normalization\n",
    "#train_data = (dat_proc_6 - dat_proc_6.mean())/(dat_proc_6.std())  \n",
    "#test_data = (dat_proc_61 - dat_proc_61.mean())/(dat_proc_61.std()) \n",
    "#print(data1.head(10))\n",
    "\n",
    "train_data = dat_proc_6\n",
    "test_data = dat_proc_61\n",
    "\n",
    "print(\"training data shape (rows, columns) =  \", train_data.shape)\n",
    "print(\"TRUE rate: \", train_labels.sum()/len(train_labels))\n",
    "\n",
    "print(\"testing data shape (rows, columns) =  \", test_data.shape)\n",
    "print(\"TRUE rate: \", test_labels.sum()/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector: [[ 0.01131223 -0.00081988  0.01386523 -0.08541791  0.01442923 -0.07223228\n",
      "   0.01540985  0.03890614  0.03326543  0.02647279 -0.03763575 -0.09030079\n",
      "   0.0049682   0.07355653 -0.1446754  -0.0892364   0.03178513  0.02560994\n",
      "  -0.05386437 -0.00730449 -0.07928107]]\n",
      "Bias: [0.00270649]\n",
      "Prediction accuracy: 0.7283950617283951\n",
      "Prediction test accuracy: 0.8469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheny\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split training dataset to 2 group\n",
    "tr_data, ts_data, tr_labels, ts_labels = train_test_split(train_data, train_labels, test_size=0.1, random_state=10)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC() #random_state=2000)\n",
    "clf.fit(tr_data, tr_labels)\n",
    "\n",
    "print(\"Weight vector: \" + str(clf.coef_))\n",
    "print(\"Bias: \" + str(clf.intercept_))\n",
    "print(\"Prediction accuracy:\", clf.score(ts_data, ts_labels))\n",
    "\n",
    "print(\"Prediction test accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01}\n",
      "Grid scores on development set:\n",
      "0.792 (+/-0.055) for {'C': 0.0001}\n",
      "0.800 (+/-0.048) for {'C': 0.001}\n",
      "0.803 (+/-0.040) for {'C': 0.01}\n",
      "0.723 (+/-0.159) for {'C': 0.1}\n",
      "0.669 (+/-0.226) for {'C': 0.5}\n",
      "0.664 (+/-0.145) for {'C': 1}\n",
      "0.695 (+/-0.217) for {'C': 10}\n",
      "0.729 (+/-0.109) for {'C': 100}\n",
      "0.750 (+/-0.159) for {'C': 1000}\n",
      "0.693 (+/-0.095) for {'C': 10000}\n",
      "Weights: [[ 0.0156459   0.00268355  0.00882215 -0.08200557 -0.01847702 -0.06631001\n",
      "   0.01402201  0.01030253  0.06087526  0.01647691 -0.05620585 -0.07752089\n",
      "   0.00443179  0.03279666 -0.10909268 -0.03479505  0.03758792  0.02945431\n",
      "  -0.04602959 -0.0006635  -0.05089783]]\n",
      "Bias: [0.00822612]\n",
      "Prediction accuracy: 0.7064676616915423\n",
      "Prediction test accuracy: 0.7653061224489796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1, 10, 100, 1000, 10000]}]\n",
    "\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "clf = GridSearchCV(LinearSVC(), tuned_parameters, cv=5, scoring='accuracy')\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print(\"Grid scores on development set:\")\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "tr_data, ts_data, tr_labels, ts_labels = train_test_split(train_data, train_labels, test_size=0.25, random_state=10)\n",
    "\n",
    "#train and test by using best parameters.\n",
    "clf = LinearSVC(random_state=10, C=clf.best_params_['C'])\n",
    "clf.fit(tr_data, tr_labels)\n",
    "\n",
    "print(\"Weights: \" + str(clf.coef_))\n",
    "print(\"Bias: \" + str(clf.intercept_))\n",
    "print(\"Prediction accuracy:\", clf.score(ts_data, ts_labels))\n",
    "\n",
    "print(\"Prediction test accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores max 0.8121212121212121\n",
      "Scores min 0.6271186440677966\n",
      "Scores mean 0.7039560665882856\n",
      "Perceptron weights for setting A: [[  326.           -95.           194.          -711.47394323\n",
      "    -74.1020093   -135.91600722   148.05995846    53.90595651\n",
      "   1490.97003651  1064.14999866 -1253.93893337  -125.85700446\n",
      "   -101.37802982  -737.633986    -197.16202807  -651.41998911\n",
      "    956.77293158   899.30708432 -1437.25508595  -181.4220304\n",
      "  -1506.03000941]]\n",
      "Perceptron bias for setting A: [-25.]\n",
      "Prediction accuracy for setting A: 0.7391304347826086\n",
      "Prediction test accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "tr_data, ts_data, tr_labels, ts_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=10)\n",
    "clf = Perceptron(random_state=1000)\n",
    "scores = cross_val_score(clf, train_data, train_labels,  cv=5, scoring='f1')\n",
    "print('Scores max', scores.max())\n",
    "print('Scores min', scores.min())\n",
    "print('Scores mean', scores.mean())\n",
    "\n",
    "#train and test on split A\n",
    "clf.fit(tr_data, tr_labels)\n",
    "\n",
    "#print(\"Setting A\")\n",
    "print(\"Perceptron weights for setting A: \" + str(clf.coef_))\n",
    "print(\"Perceptron bias for setting A: \" + str(clf.intercept_))\n",
    "print(\"Prediction accuracy for setting A:\", clf.score(ts_data, ts_labels))\n",
    "\n",
    "print(\"Prediction test accuracy:\", clf.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores max 0.7466666666666667\n",
      "Scores min 0.6184210526315789\n",
      "Scores mean 0.6726974158084287\n",
      "Accuracy 0.6708074534161491\n",
      "The depth of this tree is 15\n",
      "Prediction test accuracy: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tr_data, ts_data, tr_labels, ts_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=10)\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "scores = cross_val_score(clf, train_data, train_labels,  cv=5, scoring='f1')\n",
    "print('Scores max', scores.max())\n",
    "print('Scores min', scores.min())\n",
    "print('Scores mean', scores.mean())\n",
    "\n",
    "clf.fit(tr_data, tr_labels)\n",
    "\n",
    "print(\"Accuracy\", clf.score(ts_data, ts_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "#graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "#graph.render('graphs/tweet_dt_gini')\n",
    "\n",
    "clf.fit(train_data, train_labels)\n",
    "#print(\"Prediction eval accuracy:\", clf.score(eval_data, eval_labels))\n",
    "print(\"Prediction test accuracy:\", clf.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7204968944099379\n",
      "The depth of this tree is 18\n",
      "Prediction test accuracy: 0.7448979591836735\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(tr_data, tr_labels)\n",
    "#DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(ts_data, ts_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "#graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "#graph.render('graphs/dt_entropy')\n",
    "\n",
    "clf.fit(train_data, train_labels)\n",
    "#DecisionTreeClassifier()\n",
    "#print(\"Prediction eval accuracy:\", clf.score(eval_data, eval_labels))\n",
    "print(\"Prediction test accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores max 0.8211920529801324\n",
      "Scores min 0.7333333333333334\n",
      "Scores mean 0.7637349787982514\n",
      "['age', 'height', 'weight', 'rLen', 'rShort', 'rPT', 'rPTLPA', 'LE', 'rKME', 'rKUPE', 'rRPE ', 'lPT', 'lPGA', 'lTSPA', 'lSPA', 'lPSA', 'lCKE', 'lRUPE', 'lRPE', 'DSK', 'DLK']\n",
      "[0.04288739 0.02517597 0.02833008 0.07840926 0.03460021 0.04731739\n",
      " 0.03113707 0.03548976 0.10083155 0.05939716 0.04008755 0.04336505\n",
      " 0.02256336 0.03719496 0.02782718 0.06711636 0.05707216 0.04097391\n",
      " 0.03865806 0.04555186 0.09601372]\n",
      "Prediction test accuracy: 0.8469387755102041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=None, random_state=0, n_estimators=100, criterion='gini') \n",
    "\n",
    "scores = cross_val_score(clf, train_data, train_labels,  cv=5, scoring='f1')\n",
    "print('Scores max', scores.max())\n",
    "print('Scores min', scores.min())\n",
    "print('Scores mean', scores.mean())\n",
    "\n",
    "clf.fit(train_data, train_labels) \n",
    "print(str(list(train_data.columns)))\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "#print(\"Prediction eval accuracy:\", clf.score(eval_data, eval_labels)) \n",
    "print(\"Prediction test accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.7888198757763976\n",
      "['age', 'height', 'weight', 'rLen', 'rShort', 'rPT', 'rPTLPA', 'LE', 'rKME', 'rKUPE', 'rRPE ', 'lPT', 'lPGA', 'lTSPA', 'lSPA', 'lPSA', 'lCKE', 'lRUPE', 'lRPE', 'DSK', 'DLK']\n",
      "[[ 0.037688    0.00186248  0.03143257 -0.34211067  0.01020101 -0.16919795\n",
      "   0.08136874  0.07052542  0.10559258  0.05130595 -0.10626961 -0.11447872\n",
      "  -0.01918391  0.09076781 -0.27553906 -0.10596605  0.09685108  0.06657779\n",
      "  -0.15263384 -0.02336118 -0.1792175 ]]\n",
      "bias: [0.03136938]\n",
      "Prediction Accuracy: 0.8877551020408163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tr_data, ts_data, tr_labels, ts_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=1)\n",
    "clf = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "#train and test on setting A\n",
    "clf.fit(tr_data, tr_labels)\n",
    "print('Prediction Accuracy:', clf.score(ts_data, ts_labels))\n",
    "\n",
    "print(str(list(tr_data.columns)))\n",
    "print(clf.coef_)\n",
    "print(\"bias: \" + str(clf.intercept_))\n",
    "\n",
    "#train and test on setting B\n",
    "#clf.fit(tr_data, tr_labels)\n",
    "\n",
    "print('Prediction Accuracy:', clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 0.1}\n",
      "Grid scores on development set:\n",
      "0.779 (+/-0.048) for {'C': 0.001}\n",
      "0.800 (+/-0.053) for {'C': 0.01}\n",
      "0.808 (+/-0.050) for {'C': 0.1}\n",
      "0.802 (+/-0.054) for {'C': 0.25}\n",
      "0.799 (+/-0.054) for {'C': 0.5}\n",
      "0.805 (+/-0.042) for {'C': 0.75}\n",
      "0.800 (+/-0.044) for {'C': 1}\n",
      "0.803 (+/-0.047) for {'C': 10}\n",
      "Weights: [[ 0.03198731  0.00936145  0.02366814 -0.24812165  0.04660478 -0.15155316\n",
      "   0.05269361  0.06210675  0.10897433  0.05581873 -0.14069675 -0.14927122\n",
      "  -0.02313437  0.09703739 -0.23153881 -0.13536961  0.09991703  0.05636766\n",
      "  -0.14871567 -0.01518453 -0.1681132 ]]\n",
      "Bias: [0.02369321]\n",
      "Prediction accuracy: 0.8888888888888888\n",
      "Prediction test accuracy: 0.8877551020408163\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tr_data, ts_data, tr_labels, ts_labels = train_test_split(train_data, train_labels, test_size=0.1, random_state=1)\n",
    "\n",
    "tuned_parameters = [{'C': [1e-3, 1e-2, 0.1, 0.25, 0.5, 0.75, 1, 10]}]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(penalty= 'l2'), tuned_parameters, cv=5, scoring='accuracy')\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print(\"Grid scores on development set:\")\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "#train and test by using best parameters.\n",
    "clf = LogisticRegression(penalty= 'l2', C=clf.best_params_['C'])\n",
    "\n",
    "clf.fit(tr_data, tr_labels)\n",
    "\n",
    "print(\"Weights: \" + str(clf.coef_))\n",
    "print(\"Bias: \" + str(clf.intercept_))\n",
    "print(\"Prediction accuracy:\", clf.score(ts_data, ts_labels))\n",
    "\n",
    "print(\"Prediction test accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
